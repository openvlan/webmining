{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1reMw0MYykpg6K18pcVWpUSW4jWqe95DD","authorship_tag":"ABX9TyO0MJr0+eseKl64tPpkeF1h"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"njEh8Cemo3zb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663952440351,"user_tz":180,"elapsed":273,"user":{"displayName":"Fernando Das Neves","userId":"06324247755041763216"}},"outputId":"71287c66-9fd6-4465-8e87-c50a68387374"},"source":["# Antes de ejecutar: Activar TPUs como sigue:\n","# menu \"Entorno de Ejecucion\" -> \"Cambiar tipo de entorno de ejecucion\" -> \"Acelerador de Hardware\" = \"TPU\"\n","\n","import tensorflow as tf\n","print(\"Usandor Tensorflow version \" + tf.__version__)\n","\n","\n","if tf.test.gpu_device_name():\n","  print('Usando GPU: {}'.format(tf.test.gpu_device_name()))\n","else:\n","  print(\"Usando CPU.\")"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Usandor Tensorflow version 2.8.2\n","Usando GPU: /device:GPU:0\n"]}]},{"cell_type":"code","metadata":{"id":"IFNd6dlwv7T1","executionInfo":{"status":"ok","timestamp":1663952447388,"user_tz":180,"elapsed":1857,"user":{"displayName":"Fernando Das Neves","userId":"06324247755041763216"}}},"source":["##################################################################\n","# Este script carga VGG16, reemplaza la ultima capa de prediccion,\n","# y reentrena para clasificar imagenes de 10 categorias de flores.\n","##################################################################\n","\n","import h5py\n","from skimage.transform import resize\n","import numpy as np\n","\n","from keras.layers import Flatten, Dense, Dropout, Input, Conv2D, MaxPooling2D\n","from keras.models import Model, Sequential\n","from tensorflow.keras.optimizers import SGD\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils.vis_utils import plot_model\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.model_selection import train_test_split\n","import sklearn.preprocessing\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"fm-hHB0NyDux","executionInfo":{"status":"ok","timestamp":1663952453756,"user_tz":180,"elapsed":303,"user":{"displayName":"Fernando Das Neves","userId":"06324247755041763216"}}},"source":["# algunos parametros del entrenamiento\n","batch_size = 32 # cada batch son 32 imagenes\n","epochs = 13 # entrenamos hasta 13 epochs (pasadas sobre el dataset de entrenamiento), a menos que paremos antes por early stopping\n","epochs_to_stop_after_no_improvement = 3 # cuantas epochs consecutivas no tienen que tener mejora para aplicar early stopping\n","num_cores = 4 # cambiar este numero a la cantidad de cores de su cpu\n","\n","# parametros del descenso de gradiente\n","learning_rate=0.001\n","learning_rate_decay=1e-6\n","learning_rate_momentum=0.7"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"iI_H5qI_yF9w","executionInfo":{"status":"ok","timestamp":1663952456234,"user_tz":180,"elapsed":278,"user":{"displayName":"Fernando Das Neves","userId":"06324247755041763216"}}},"source":["def preprocesar_imagen_como_caffe(image:np.ndarray) -> np.ndarray:\n","    \"\"\"\n","    Transforma las imagenes al formato con el que fue entrenado el modelo de VGG16 que estamos usando.\n","    :param image: Una imagen representada como una matriz de (largo en pixels, alto en pixels, 3 canales)\n","    :return La imagen transformada.\n","    \"\"\"\n","    # pasar imagen de  'RGB'->'BGR', porque el modelo ya entrenado de VGG16 que estamos usando proviene de Caffe, y fue entrenado en ese orden de channels\n","    image = image[:, :, ::-1]\n","    # central valor de los pixels alrededor del valor medio de cada canal en el conj. de entrenamiento,\n","    # esto se calcula simplemente promediando todos los valores de cada canal en todas las imagenes de entrenamiento en imagenet.\n","    image[:, :, 0] -= 103.939\n","    image[:, :, 1] -= 116.779\n","    image[:, :, 2] -= 123.68\n","    return image\n","\n","\n","def rescalar_imagenes(flower_images:np.ndarray) -> np.ndarray:\n","    \"\"\"\n","    Cambia el tama単o de las imagenes de flores al tama単o con el que esta entrenada VGG16: 224x224 pixels\n","    :param flower_images: Una matriz de (nro_imagenes, ancho en pixels, alto en pixels, 3 canales); cada valor de la matriz esta entre 0 y 255.\n","    :return: Otra matriz de las mismas dimensiones de 'flowers' pero con todos los valores entre 0 y 1.\n","    \"\"\"\n","    rescaled_images = np.empty((flower_images.shape[0], 224, 224, flower_images.shape[3]), dtype=flower_images.dtype)\n","    for i in range(0, flower_images.shape[0]):\n","        rescaled_images[i, 0:224, 0:224, ] = resize(flower_images[i] / 255.0, (224, 224), anti_aliasing=True) * 255.0\n","    return rescaled_images\n","\n","\n","def encode_onehot_labels(labels:np.ndarray) ->np.ndarray:\n","    \"\"\"\n","     Cambia la codificacion de las categorias de flores a one-hot encoding, que es lo que necesitamos para entrenar la NN.\n","     :param labels: Una lista o arreglo de strings, el i-avo string es la categoria de la i-ava imagen de entrenamiento.\n","     :return una matriz de tama単o (cantidad de ejemplos en labels, cantidad de categorias en 'labels') donde cada celda es 1 o 0. Hay 1 solo 1 por fila.\n","    \"\"\"\n","    label_binarizer = sklearn.preprocessing.LabelBinarizer()\n","    label_binarizer.fit(range(max(labels) + 1))\n","    return label_binarizer.transform(labels)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"Emb12Xn9yLhM","executionInfo":{"status":"ok","timestamp":1663952461042,"user_tz":180,"elapsed":275,"user":{"displayName":"Fernando Das Neves","userId":"06324247755041763216"}}},"source":["def VGG_16():\n","    img_input = Input(shape=(224,224,3)) # tama単o de imagenes y 3 canales de colores\n","\n","    # Block 1\n","    output = Conv2D(64, (3, 3),\n","                      activation='relu',\n","                      padding='same',\n","                      name='block1_conv1')(img_input)\n","    output = Conv2D(64, (3, 3),\n","                      activation='relu',\n","                      padding='same',\n","                      name='block1_conv2')(output)\n","    output = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(output)\n","\n","    # Block 2\n","    output = Conv2D(128, (3, 3),\n","                      activation='relu',\n","                      padding='same',\n","                      name='block2_conv1')(output)\n","    output = Conv2D(128, (3, 3),\n","                      activation='relu',\n","                      padding='same',\n","                      name='block2_conv2')(output)\n","    output = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(output)\n","\n","    # Block 3\n","    output = Conv2D(256, (3, 3),\n","                      activation='relu',\n","                      padding='same',\n","                      name='block3_conv1')(output)\n","    output = Conv2D(256, (3, 3),\n","                      activation='relu',\n","                      padding='same',\n","                      name='block3_conv2')(output)\n","    output = Conv2D(256, (3, 3),\n","                      activation='relu',\n","                      padding='same',\n","                      name='block3_conv3')(output)\n","    output = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(output)\n","\n","    # Block 4\n","    output = Conv2D(512, (3, 3),\n","                      activation='relu',\n","                      padding='same',\n","                      name='block4_conv1')(output)\n","    output = Conv2D(512, (3, 3),\n","                      activation='relu',\n","                      padding='same',\n","                      name='block4_conv2')(output)\n","    output = Conv2D(512, (3, 3),\n","                      activation='relu',\n","                      padding='same',\n","                      name='block4_conv3')(output)\n","    output = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(output)\n","\n","    # Block 5\n","    output = Conv2D(512, (3, 3),\n","                      activation='relu',\n","                      padding='same',\n","                      name='block5_conv1')(output)\n","    output = Conv2D(512, (3, 3),\n","                      activation='relu',\n","                      padding='same',\n","                      name='block5_conv2')(output)\n","    output = Conv2D(512, (3, 3),\n","                      activation='relu',\n","                      padding='same',\n","                      name='block5_conv3')(output)\n","    output = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(output)\n","\n","    # capa de clasificacion\n","    output = Flatten(name='flatten')(output)\n","    output = Dense(4096, activation='relu', name='fc1')(output)\n","    output = Dense(4096, activation='relu', name='fc2')(output)\n","    output = Dense(1000, activation='softmax', name='predictions')(output)\n","\n","    return Model(inputs=img_input, outputs=output, name='vgg16')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tv7VlazpyORO","executionInfo":{"status":"ok","timestamp":1663952486988,"user_tz":180,"elapsed":3422,"user":{"displayName":"Fernando Das Neves","userId":"06324247755041763216"}}},"source":["# leer el dataset de 210 imagenes de flores junto con y sus etiquetas\n","dataset = h5py.File(\"/content/drive/MyDrive/collab/transfer_learning/flowers_dataset/10FlowerColorImages.h5\",'r')\n","# El [()] indica que lea el dataset completo a memoria, en vez de leerlo bajo demanda\n","images = dataset['images'][()]\n","image_labels = dataset['labels'][()]\n","images = rescalar_imagenes(images)\n","onehot_labels = encode_onehot_labels(image_labels)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZXfOOjk9y557","executionInfo":{"status":"ok","timestamp":1663952491587,"user_tz":180,"elapsed":570,"user":{"displayName":"Fernando Das Neves","userId":"06324247755041763216"}}},"source":["# armar la arquitectura de la red neuronal\n","pretrained_vgg16 = VGG_16()"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJdWYYMhy8NE","executionInfo":{"status":"ok","timestamp":1663952504922,"user_tz":180,"elapsed":12328,"user":{"displayName":"Fernando Das Neves","userId":"06324247755041763216"}}},"source":["# El modelo tiene los pesos del entrenamiento con Caffe, donde el dataset tiene los pixels en orden 'BGR'\n","#  y c/pixel centrado sobre la media del dataset imagenet = [103.939, 116.779, 123.68]\n","# Las imagenes nuevas tienen que tener exactamente esta transformacion\n","pretrained_vgg16.load_weights('/content/drive/MyDrive/collab/transfer_learning/imagenet_dataset/vgg16_weights.h5')"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"JvblPEJ0i67t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663952504925,"user_tz":180,"elapsed":30,"user":{"displayName":"Fernando Das Neves","userId":"06324247755041763216"}},"outputId":"2ea652d1-dedc-4430-a62d-16b28a9c9080"},"source":["# Aqui eliminamos el block5 COMPLETO de VGG 16 (el ultimo bloque de convoluciones antes de clasificar),\n","# y conectamos la salida del block 4 a las 2 capas densas de clasificaci坦n.\n","# Lo eliminamos creando una nueva capa \"replaced_flatten\" cuya entrada es la salida de \"block4_pool\".\n","# De ahi para abajo repetimos el esquema de 3 capas de clasificaci坦n.\n","# Pueden ver en \"summary\" que el block 5 no est叩 mas.\n","new_layer = Flatten(name='replaced_flatten')(pretrained_vgg16.get_layer(\"block4_pool\").output)\n","new_layer = Dense(4096, activation='relu', name='replaced_fc1')(new_layer)\n","new_layer = Dense(4096, activation='relu', name='replaced_fc2')(new_layer)\n","new_layer = Dense(10, activation=\"softmax\", name=\"predict_10flowers\")(new_layer)\n","pretrained_vgg16 = Model(pretrained_vgg16.input, new_layer)\n","pretrained_vgg16.summary()"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," replaced_flatten (Flatten)  (None, 100352)            0         \n","                                                                 \n"," replaced_fc1 (Dense)        (None, 4096)              411045888 \n","                                                                 \n"," replaced_fc2 (Dense)        (None, 4096)              16781312  \n","                                                                 \n"," predict_10flowers (Dense)   (None, 10)                40970     \n","                                                                 \n","=================================================================\n","Total params: 435,503,434\n","Trainable params: 435,503,434\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"3096j1L7yVfx","executionInfo":{"status":"ok","timestamp":1663952521195,"user_tz":180,"elapsed":288,"user":{"displayName":"Fernando Das Neves","userId":"06324247755041763216"}}},"source":["# setear a todas las capas, excepto las 3 ultimas capas de clasificacion\n","# como \"no entrenable\" (los pesos no se actualizaran)\n","for layer in pretrained_vgg16.layers[:-3]:\n","    layer.trainable = False\n","\n","# crear un nuevo modelo cuya salida es la nueva capa\n","new_model = Model(inputs=pretrained_vgg16.input, outputs=new_layer)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"5q_Jonghyesi","executionInfo":{"status":"ok","timestamp":1663952523482,"user_tz":180,"elapsed":279,"user":{"displayName":"Fernando Das Neves","userId":"06324247755041763216"}}},"source":["# compilar el modelo con SGD/momentum optimizer\n","# y un learning rate muuuuy lento\n","sgd = SGD(learning_rate=learning_rate, decay=learning_rate_decay, momentum=learning_rate_momentum, nesterov=True)\n","# regla en Keras:\n","# si loss=categorical_crossentropy => metrics=categorical_accuracy\n","# si loss=binary_crossentropy y mas de 2 clases => metrics=categorical_accuracy, sino metrics=binary_accuracy\n","new_model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"2iSzocdpyjei","executionInfo":{"status":"ok","timestamp":1663952528153,"user_tz":180,"elapsed":314,"user":{"displayName":"Fernando Das Neves","userId":"06324247755041763216"}}},"source":["# didivir el dataset en 70% entrenamiento y 30% test\n","X_train, X_test, y_train, y_test = train_test_split(images, onehot_labels, train_size=0.7, test_size=0.3, shuffle=True, stratify=image_labels)\n","\n","# aumentar la cantidad de ejemplos de entrenamiento, inventando variaciones de las imagenes\n","train_datagen = ImageDataGenerator(\n","    width_shift_range = 0.1,\n","    height_shift_range=0.1,\n","    shear_range=0.2,\n","    zoom_range=[0.8, 1.4],\n","    horizontal_flip=True,\n","    rotation_range=10,\n","    preprocessing_function=preprocesar_imagen_como_caffe\n",")\n","\n","# testear con los casos de prueba sin rotar, cambiar tama単o ni nada, solo acomodados a la manera en que fue entrenada la NN\n","test_datagen = ImageDataGenerator(preprocessing_function=preprocesar_imagen_como_caffe)\n","\n","train_generator = train_datagen.flow(\n","    X_train,\n","    y_train,\n","    batch_size=batch_size,\n",")\n","\n","validation_generator = test_datagen.flow(\n","    X_test,\n","    y_test\n",")"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"nFgMzQNoymQm"},"source":["# entrenar y guarda el mejor resultado\n","new_model.fit(\n","    train_generator,\n","    steps_per_epoch=len(y_train) // batch_size,\n","    epochs=epochs,\n","    validation_data=validation_generator,\n","    validation_steps=len(y_test) // batch_size,\n","    use_multiprocessing=True,\n","    workers=num_cores,\n","    # parar el entrenamiento si no mejora en 3 epochs consecutivas; guardar el mejor modelo hasta ese momento al final de cada epoch\n","    callbacks=[EarlyStopping(monitor='val_categorical_accuracy', patience=epochs_to_stop_after_no_improvement, verbose=1),\n","               ModelCheckpoint('/content/drive/MyDrive/collab/transfer_learning/vgg16_retrained_10flowers_v2.h5', verbose=1, monitor='val_categorical_accuracy', save_best_only=True, mode='auto')]\n",")\n","\n","print(\"Entrenamiento finalizado.\")"],"execution_count":null,"outputs":[]}]}